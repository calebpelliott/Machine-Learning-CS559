{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f920a13",
   "metadata": {},
   "source": [
    "# <center> CS559 Homework#3: Decision Tree and Ensemble Methods</center>\n",
    "## <center> Due: 11/8/2021 Monday at 11:59 PM</center>\n",
    "\n",
    "\n",
    "In this assignment, you are going to implement four classifiers - **decision tree, random forest, adaboost, and gradient boost**. \n",
    "Then check the performance with `sklearn` built-in algorithms.\n",
    "In this work, splitting into train and test sets is not necessary. \n",
    "\n",
    "The provided data has four columns - three features (a, b, and c) and the target (class). Three features are continuous data and the target is a binary, 0 or 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f0fa8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ade2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./F21_CS559_HW3_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89c8ebae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4202</td>\n",
       "      <td>-4.3507</td>\n",
       "      <td>10.3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.7044</td>\n",
       "      <td>-4.4601</td>\n",
       "      <td>10.6803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8075</td>\n",
       "      <td>-4.0894</td>\n",
       "      <td>10.6259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2771</td>\n",
       "      <td>-4.0349</td>\n",
       "      <td>10.1166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.6447</td>\n",
       "      <td>-3.5968</td>\n",
       "      <td>10.2936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a       b        c  class\n",
       "0  9.4202 -4.3507  10.3764      1\n",
       "1  9.7044 -4.4601  10.6803      1\n",
       "2  9.8075 -4.0894  10.6259      1\n",
       "3  9.2771 -4.0349  10.1166      1\n",
       "4  9.6447 -3.5968  10.2936      1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b0d970",
   "metadata": {},
   "source": [
    "### Question 1: Decisition Tree Classifier\n",
    "- A simple DT implementation (10 pts.)\n",
    "    - to make the problem simple, implement a decision tree with depth of 3 (the root index is 0).\n",
    "    - calculate the gini index for each attribute and pick the best attribute for each node.\n",
    "    - calculate the accuracy using accuracy score. \n",
    "- Classification using DecistionTreeClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5f0f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTree(df):\n",
    "    X = df.drop('class', 1)\n",
    "    y = df['class']\n",
    "    for x in df.columns[0:-1]:\n",
    "        #Cut by mean\n",
    "        mean = df[x].mean()\n",
    "        min = df[x].min()\n",
    "        max = df[x].max()\n",
    "        mid = (max + min) /2\n",
    "\n",
    "        df[x] = pd.cut(df[x], bins=[min, mid, max], labels=[0,1])\n",
    "    def calcGini(item):\n",
    "    #Calculate gini\n",
    "        count = Counter(item)\n",
    "        total = len(item)\n",
    "        count_list = [count[0], count[1]]\n",
    "        freqs = [float(x)/total for x in count_list]\n",
    "        gini_scores = [x*(1-x) for x in freqs]\n",
    "        final_score = sum(gini_scores)\n",
    "        return final_score\n",
    "\n",
    "    def getSortedFeatureScores(df):\n",
    "        scores = {}\n",
    "        for feat in df.columns[0:-1]:\n",
    "            L=list(df[feat])\n",
    "            scores[feat] = calcGini(L)\n",
    "        return sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    feat_order = []\n",
    "    pred = {}\n",
    "\n",
    "    node = getSortedFeatureScores(df)\n",
    "    feat_order.append(node[0][0])\n",
    "    l_df = df.loc[df[node[0][0]] == 0]\n",
    "    r_df = df.loc[df[node[0][0]] == 1]\n",
    "    #       c\n",
    "    #     0   1\n",
    "    #   a       a\n",
    "    #  0 1     0 1\n",
    "    # b   b    b  b\n",
    "    #0 1 0 1  0 1 0 1\n",
    "    #2 2 2 2  1 1 1 2\n",
    "    #process left\n",
    "    n_df = l_df.drop(node[0][0],1)\n",
    "    node2 = getSortedFeatureScores(n_df)\n",
    "    ll_df = n_df.loc[n_df[node2[0][0]] == 0]\n",
    "    ll_df = ll_df.drop(node2[0][0],1)\n",
    "    rr_df = n_df.loc[n_df[node2[0][0]] == 1]\n",
    "    rr_df = rr_df.drop(node2[0][0],1)\n",
    "    # percentage of b1 -> class 1 vs class 2\n",
    "    total = len(ll_df)\n",
    "    b0 = ll_df[ll_df[node2[1][0]] ==0]\n",
    "    pc1 = len(b0[b0['class'] == 1]) / len(b0)\n",
    "    pc2 = len(b0[b0['class'] == 2]) / len(b0)\n",
    "    if pc1 > pc2:\n",
    "        pred['000'] = 1\n",
    "    else:\n",
    "        pred['000'] = 2\n",
    "\n",
    "    b1 = ll_df[ll_df[node2[1][0]] ==1]\n",
    "    pc1 = len(b1[b1['class'] == 1]) / len(b1)\n",
    "    pc2 = len(b1[b1['class'] == 2]) / len(b1)\n",
    "    if pc1 > pc2:\n",
    "        pred['001'] = 1\n",
    "    else:\n",
    "        pred['001'] = 2\n",
    "\n",
    "    b0 = rr_df[rr_df[node2[1][0]] ==0]\n",
    "    pc1 = len(b0[b0['class'] == 1]) / len(b0)\n",
    "    pc2 = len(b0[b0['class'] == 2]) / len(b0)\n",
    "    if pc1 > pc2:\n",
    "        pred['010'] = 1\n",
    "    else:\n",
    "        pred['010'] = 2\n",
    "\n",
    "    b1 = rr_df[rr_df[node2[1][0]] ==1]\n",
    "    pc1 = len(b1[b1['class'] == 1]) / len(b1)\n",
    "    pc2 = len(b1[b1['class'] == 2]) / len(b1)\n",
    "    if pc1 > pc2:\n",
    "        pred['011'] = 1\n",
    "    else:\n",
    "        pred['011'] = 2\n",
    "\n",
    "\n",
    "    #process right\n",
    "    n_df = r_df.drop(node[0][0],1)\n",
    "    node2 = getSortedFeatureScores(n_df)\n",
    "    ll_df = n_df.loc[n_df[node2[0][0]] == 0]\n",
    "    ll_df = ll_df.drop(node2[0][0],1)\n",
    "    rr_df = n_df.loc[n_df[node2[0][0]] == 1]\n",
    "    rr_df = rr_df.drop(node2[0][0],1)\n",
    "    # percentage of b1 -> class 1 vs class 2\n",
    "    total = len(ll_df)\n",
    "    b0 = ll_df[ll_df[node2[1][0]] ==0]\n",
    "    pc1 = len(b0[b0['class'] == 1]) / len(b0)\n",
    "    pc2 = len(b0[b0['class'] == 2]) / len(b0)\n",
    "    if pc1 > pc2:\n",
    "        pred['100'] = 1\n",
    "    else:\n",
    "        pred['100'] = 2\n",
    "\n",
    "    b1 = ll_df[ll_df[node2[1][0]] ==1]\n",
    "    pc1 = len(b1[b1['class'] == 1]) / len(b1)\n",
    "    pc2 = len(b1[b1['class'] == 2]) / len(b1)\n",
    "    if pc1 > pc2:\n",
    "        pred['101'] = 1\n",
    "    else:\n",
    "        pred['101'] = 2\n",
    "\n",
    "    b0 = rr_df[rr_df[node2[1][0]] ==0]\n",
    "    pc1 = len(b0[b0['class'] == 1]) / len(b0)\n",
    "    pc2 = len(b0[b0['class'] == 2]) / len(b0)\n",
    "    if pc1 > pc2:\n",
    "        pred['110'] = 1\n",
    "    else:\n",
    "        pred['110'] = 2\n",
    "\n",
    "    b1 = rr_df[rr_df[node2[1][0]] ==1]\n",
    "    pc1 = len(b1[b1['class'] == 1]) / len(b1)\n",
    "    pc2 = len(b1[b1['class'] == 2]) / len(b1)\n",
    "    if pc1 > pc2:\n",
    "        pred['111'] = 1\n",
    "    else:\n",
    "        pred['111'] = 2\n",
    "\n",
    "    pred_test = []\n",
    "    #do predictions\n",
    "    for index, row in df.iterrows():\n",
    "        key = str(row['c']) + str(row['a']) + str(row['b'])\n",
    "        try:\n",
    "            pred_test.append(pred[key])\n",
    "        except:\n",
    "            pred_test.append(1)\n",
    "    score = accuracy_score(pred_test, y)\n",
    "    return score\n",
    "selfscore = DecisionTree(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51be80b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X,y)\n",
    "score = dtc.score(X,y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd62b825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implement score: 0.972\n",
      "sklearn score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Implement score: {selfscore}\")\n",
    "print(f\"sklearn score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1409c260",
   "metadata": {},
   "source": [
    "### Question 2: Random Forest Classifier\n",
    "- A simle RF implementation (10 pts)\n",
    "    - make a bootstrap baggin function to make 3 samples.\n",
    "    - for each sample, run a simple DT from question 1.\n",
    "    - then average the accuracy. \n",
    "- Classification using RandomForestClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76d14a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "df = pd.read_csv('./F21_CS559_HW3_data.csv')\n",
    "\n",
    "def buildRandomForest(df):\n",
    "    ratio = .5\n",
    "    rand_i = []\n",
    "    needed= round(len(df) * ratio)\n",
    "\n",
    "    for i in range(needed):\n",
    "        rand_i.append(randrange(len(df)))\n",
    "    new_df = df.iloc[rand_i,:]\n",
    "    return new_df\n",
    "\n",
    "all_scores = []\n",
    "for _ in range(3):\n",
    "    rforest = buildRandomForest(df)\n",
    "    r_score = DecisionTree(rforest)\n",
    "    all_scores.append(r_score)\n",
    "selfscore = sum(all_scores) / len(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12b6c1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X,y)\n",
    "score = rfc.score(X,y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ede15d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest Implement score: 0.9632\n",
      "sklearn score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random forest Implement score: {selfscore}\")\n",
    "print(f\"sklearn score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27c04de",
   "metadata": {},
   "source": [
    "### Question 3: AdaBoost Classifier\n",
    "- AB implementation (15 pts)\n",
    "- Classification using AdaBoostClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47f7e059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "2495    1\n",
      "2496    1\n",
      "2497    1\n",
      "2498    1\n",
      "2499    1\n",
      "Length: 2500, dtype: int32\n",
      "0.4996\n"
     ]
    }
   ],
   "source": [
    "def AdaBoost(X, y, rounds = 100):\n",
    "    alphas = [] \n",
    "    models = []\n",
    "\n",
    "    w = np.array([1/len(y)]*len(y))\n",
    "    for m in range(0, rounds):\n",
    "        \n",
    "        \n",
    "        \n",
    "        dtc = DecisionTreeClassifier()\n",
    "        dtc.fit(X, y, sample_weight = w)\n",
    "        y_pred = dtc.predict(X)\n",
    "        \n",
    "        models.append(dtc)\n",
    "        errors = []\n",
    "        for i in range(len(y)):\n",
    "            if y[i] != y_pred[i]:\n",
    "                errors.append(True)\n",
    "            else:\n",
    "                errors.append(False)\n",
    "        errors = np.array(errors)\n",
    "        error = sum(w*errors.astype(int))/sum(w)\n",
    "\n",
    "        a = np.log((1 - error) / error)\n",
    "        alphas.append(a)\n",
    "\n",
    "        errors = []\n",
    "        for i in range(len(y)):\n",
    "            if y[i] != y_pred[i]:\n",
    "                errors.append(True)\n",
    "            else:\n",
    "                errors.append(False)\n",
    "        errors = np.array(errors)\n",
    "        w2 = []\n",
    "        for i in range(len(w)):\n",
    "            if errors[i]:\n",
    "                new = w[i] * np.exp(a)\n",
    "                w2.append(new)\n",
    "            else:\n",
    "                w2.append(w[i])\n",
    "        w = np.array(w2)\n",
    " \n",
    "    n_df = pd.DataFrame(index = range(len(X)), columns = range(rounds)) \n",
    "    for round in range(rounds):\n",
    "        r_model = models[round]\n",
    "        r_al = alphas[round]\n",
    "        r_pred = r_model.predict(X)*r_al\n",
    "        n_df.iloc[:,m] = r_pred\n",
    "\n",
    "    # Calculate final predictions\n",
    "    fin = n_df.T.sum()\n",
    "    fin = np.sign(fin)\n",
    "\n",
    "    return fin.astype(int)\n",
    "\n",
    "\n",
    "pred = AdaBoost(X,y,500)\n",
    "selfscore = accuracy_score(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X,y)\n",
    "score = abc.score(X,y)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd5831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e102e54",
   "metadata": {},
   "source": [
    "### Question 4: Gradient Boost Classifier\n",
    "- GB implementation (15 pts)\n",
    "- Classification using GradientBoostingClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6087e3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./F21_CS559_HW3_data.csv')\n",
    "def GradientBoost(model, X, y):\n",
    "    times = 10\n",
    "    lr = 0.1\n",
    "\n",
    "    yt = np.array([np.mean(y)]*len(y))\n",
    "    w = y - yt\n",
    "\n",
    "    for _ in range(times):\n",
    "        model = model.fit(X, y, sample_weight=w)\n",
    "        yt += lr * model.predict(X)\n",
    "        w = y - yt\n",
    "\n",
    "    return model.predict(X)\n",
    "\n",
    "X = df.drop('class', 1)\n",
    "y = df['class']\n",
    "mygb = GradientBoost(DecisionTreeClassifier(), X,y)\n",
    "print(mygb)\n",
    "selfscore = accuracy_score(mygb, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96ed0fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X,y)\n",
    "pred = gbc.predict(X)\n",
    "print(accuracy_score(y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82528423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Implement score: 0.5004\n",
      "sklearn score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"GB Implement score: {selfscore}\")\n",
    "print(f\"sklearn score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b13a60-6edf-4a21-b834-9ddbfa859e89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
