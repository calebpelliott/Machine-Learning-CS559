{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dated-minimum",
   "metadata": {},
   "source": [
    "**<center>CS559 Fall 2021 Midterm</center>**\n",
    "**<center>Due: in 90 minutes <center>**\n",
    "\n",
    "The second part of the midterm contains the computations to solve machine learning problems. It is an open-notes exam and students can only use lecture notes and demonstration files provided from the class. \n",
    "Students are not allowed to use any other modules than $\\color{red}{\\textbf{Numpy, Pandas, and Matplot}}$. \n",
    "\n",
    "Although there are no plotting questions, students are welcome to display plots to confirm their answers. \n",
    "\n",
    "Students must submit the exam **90 minutes from the start**. \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sunrise-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-match",
   "metadata": {},
   "source": [
    "## Question 1 [20 pts]\n",
    "\n",
    "This question is a gradient descent problem and students are required to find a weight vector of the actual quadratic function of the provided data, `gradient_question.csv`. The dataset has two columns, x and y, where y is the true target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-shoot",
   "metadata": {},
   "source": [
    "### 1-1.\n",
    "Write a short function called `my_gradient()` that optimizes the weight vector using the squared error function and returns the weight vector when the acceptance of error is below 0.05 and the learning rate $\\eta$ is 0.001. [12 pts] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stuck-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gradient(X, y):\n",
    "    n = .001\n",
    "    e = 1\n",
    "    num_samps = len(X)\n",
    "    m = np.random.random(1)[0]\n",
    "    b = np.random.random(1)[0]\n",
    "    w = None\n",
    "    while(e > .05):\n",
    "        temp = m*X + b\n",
    "        diff = y-temp\n",
    "        \n",
    "        m_deriv = X.dot(diff)\n",
    "        m_deriv = m_deriv.sum() / num_samps\n",
    "        m = m - (n * (-2 * m_deriv))\n",
    "        \n",
    "        b_deriv = diff.sum() / num_samps\n",
    "        b = b - (n *(-2 * b_deriv))\n",
    "        updated = m*X + b\n",
    "        mse = ((y - updated)**2).mean(axis=0)\n",
    "        e =mse\n",
    "        if mse < .05:\n",
    "            w = [b, m]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-jamaica",
   "metadata": {},
   "source": [
    "### 1-2.\n",
    "\n",
    "Using the optimized weight vector, find the local maximum. [8 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "disciplinary-amsterdam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "### code starts here. \n",
    "df = pd.read_csv('./gradient_question.csv')\n",
    "\n",
    "df.plot(x='x', y='y', style='o')\n",
    "\n",
    "w= my_gradient(df['x'], df['y'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-bridal",
   "metadata": {},
   "source": [
    "## Question 2 [20 pts]\n",
    "\n",
    "This question is a probability classification problem. Assuming that training a mixture of Gaussians model by maximum likelihood, students will find P(1|0.75) using data `Probability_Classification.csv`. In the dataset, there are two columns, **x** and **class**, where the **class** is the binary class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-liechtenstein",
   "metadata": {},
   "source": [
    "### 2-1\n",
    "Find the prior, expected value, and variance for each class. [12 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "simple-decline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'x'}>,\n",
       "        <AxesSubplot:title={'center':'class'}>]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### code starts here\n",
    "df = pd.read_csv('./Probability_Classification.csv')\n",
    "df_0 = df[df['class'] == 0]\n",
    "df_1 = df[df['class'] == 1]\n",
    "var_0 = df_0.var()['x']\n",
    "var_1 = df_1.var()['x']\n",
    "\n",
    "#Assuming gaussian distribution\n",
    "E_x_0 = df_0.mean()['x']\n",
    "E_x_1 = df_1.mean()['x']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-affect",
   "metadata": {},
   "source": [
    "### 2-2\n",
    "Find the probability P(1|0.75)? [8 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code starts here\n",
    "= P(.75|1)P(1)/P(.75)\n",
    "=CDF_class1(.75)* (num(class1)/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-fundamental",
   "metadata": {},
   "source": [
    "### Question 3 [20 pts]\n",
    "\n",
    "This question is a linear classification problem. Students are going to build the binary SVM and Logistic Regression to classify the data set, `LR_SVM.csv`. In the dataset, there are four columns, **x1**, **x2**, **y**, and **a**, where **y** is the class and **a** is the Lagrange Multiplier. You can attack the problem by "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-seller",
   "metadata": {},
   "source": [
    "### 3-1\n",
    "Using the weight vector $\\vec{w}=[-5.653, 1.199, 0.822]$, build a Logisitc Regression Classifier, $\\sigma(\\vec{w}\\cdot \\vec{x})\\ge0.5$, and classify each $\\vec{x}=[x1,x2]^T$. Please do not copy and use the implemented logistic regression from Assignment 2. Determine which class $\\vec{x}=[3,3]^T$ belongs to. [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "informational-relations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x1   x2\n",
      "0  4.0  2.9\n",
      "1  4.0  4.0\n",
      "2  1.0  2.5\n",
      "3  2.5  1.0\n",
      "4  4.9  4.5\n",
      "5  1.9  1.9\n",
      "6  3.5  4.0\n",
      "7  0.5  1.5\n",
      "8  2.0  2.1\n",
      "9  4.5  2.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### code starts here\n",
    "df = pd.read_csv('./LR_SVM.csv')\n",
    "X = pd.DataFrame()\n",
    "X['x1'] = df['x1'] \n",
    "X['x2'] = df['x2'] \n",
    "print(X)\n",
    "X= X.to_numpy()\n",
    "w=np.array([[1.199],[0.822]])\n",
    "b= -5.653\n",
    "pred = (X.dot(w) + b)\n",
    "pred = [-1 if x <= .5 else 1 for x in pred]\n",
    "\n",
    "x_33 = 1.199*3 + .822*3 - 5.653\n",
    "x_33 = -1 if x_33 <= .5 else 1\n",
    "x_33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-wisdom",
   "metadata": {},
   "source": [
    "### 3-2\n",
    "\n",
    "You are going to build a SVM classifier  by following:\n",
    "a) Find the equation of the SVM hyperplane h(x) and classify each $\\vec{x}$, b) calculate the distance of each point from the hyperplane and print the support vectors, and c) classify the point $\\vec{x}=[3,3]^T$ using h(x) from a). [10 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code starts here\n",
    "\n",
    "Ran out of time but here I would apply a kernel function in order seperate the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
